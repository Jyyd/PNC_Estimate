{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: jyyd23@mails.tsinghua.edu.cn\n",
    "Date: 2024-04-28 11:51:04\n",
    "LastEditors: jyyd23@mails.tsinghua.edu.cn\n",
    "LastEditTime: 2024-05-09 16:35:29\n",
    "FilePath: CAMS_downscale\\cams_train_pred.ipynb\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import scipy.io as sio\n",
    "import time\n",
    "import dataframe_image as dfi\n",
    "import os, sys\n",
    "os.chdir(sys.path[0])\n",
    "from tqdm import trange, tqdm\n",
    "import seaborn as sns\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn import neighbors, svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "\n",
    "from joblib import dump, load\n",
    "import concurrent.futures\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score,cross_val_predict,cross_validate, RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set(rc={'figure.dpi': 600})\n",
    "\n",
    "evsall = []\n",
    "maeall = []\n",
    "mseall = []\n",
    "r2all = []\n",
    "\n",
    "\n",
    "def pred_plot(y_test, y_pred, resid):\n",
    "    print('----------------------------------')\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    evs = explained_variance_score(y_test, y_pred)\n",
    "    print('MSE: ', mse)\n",
    "    print('MAE: ', mae)\n",
    "    print('r2 score: ', r2)\n",
    "    print('Explained_variance: ', evs)\n",
    "    return mse,mae,r2,evs\n",
    "def predpnc(model_fit, x_test, y_test, pncdata2020):\n",
    "    pred = model_fit.predict(x_test)\n",
    "    resid = pred - y_test\n",
    "    mse, mae, r2, evs = pred_plot(y_test, pred, resid)\n",
    "    pred = pd.DataFrame(pred)\n",
    "    resid = pd.DataFrame(resid)\n",
    "    data2020_pred = pd.concat([pncdata2020, pred, resid], axis=1)\n",
    "    return data2020_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traindata_train: (105024, 12)\n",
      "traindata_test: (113994, 12)\n",
      "x_train: (105024, 10)\n",
      "y_train: (105024,)\n",
      "x_test: (113994, 10)\n",
      "y_test: (113994,)\n"
     ]
    }
   ],
   "source": [
    "pollution = 'PM2.5'\n",
    "\n",
    "trainpath = '../dataset/trainpredata/trainData2312/'+ pollution + '_trainData.csv'\n",
    "traindata = pd.read_csv(trainpath)\n",
    "stations = ['BAS', 'BER', 'HAE', 'LUG', 'RIG', 'LAU', 'ZUE', 'DUE', 'SIO', 'MAG',\n",
    "            'PAY', 'TAN', 'CHA', 'DAV', 'JUN']\n",
    "sta = []\n",
    "for i in range(len(stations)):\n",
    "    temp = [stations[i] for m in range(8760+8784)]\n",
    "    sta.extend(temp)\n",
    "sta = pd.DataFrame(sta)\n",
    "# PM2.5\n",
    "traindata = pd.concat([traindata, sta], axis=1)\n",
    "traindata.columns = ['cams', 'radiation', 'temperature', 'precipitation', 'humidity',\n",
    "                       'Speed', 'road', 'hour', 'month', 'weekday', 'measurements', 'sta']\n",
    "# OTHERS\n",
    "traindata = traindata.apply(pd.to_numeric,errors=\"ignore\")\n",
    "traindata = traindata[['sta', 'cams', 'radiation', 'temperature', 'precipitation', 'humidity',\n",
    "                       'Speed', 'road', 'hour', 'month', 'weekday', 'measurements']]\n",
    "slices_train = []\n",
    "slices_test = []\n",
    "for i in range(16):\n",
    "    # print('----------------------------------')\n",
    "    # print('slice:', i)\n",
    "    start_train = i * (8760 + 8784)\n",
    "    end_train = start_train + 8760\n",
    "    # print(start_train, end_train)\n",
    "    slices_train.append(traindata.iloc[start_train:end_train, :])\n",
    "    start_test = 8760 + i * (8760 + 8784)\n",
    "    end_test = start_test + 8784\n",
    "    # print(start_test, end_test)\n",
    "    slices_test.append(traindata.iloc[start_test:end_test, :])\n",
    "traindata_train = pd.concat(slices_train)\n",
    "traindata_test = pd.concat(slices_test)\n",
    "\n",
    "traindata = traindata.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how='any')\n",
    "traindata_train = traindata_train.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how='any')\n",
    "traindata_test = traindata_test.replace([np.inf, -np.inf], np.nan).dropna(axis=0, how='any')\n",
    "traindata_train = traindata_train.reset_index(drop=True)\n",
    "traindata_test = traindata_test.reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler().fit(traindata.iloc[:, 1:-1])\n",
    "x_train = scaler.transform(traindata_train.iloc[:, 1:-1])\n",
    "y_train = traindata_train.iloc[:, -1]\n",
    "x_test = scaler.transform(traindata_test.iloc[:, 1:-1])\n",
    "y_test = traindata_test.iloc[:, -1]\n",
    "\n",
    "print('traindata_train:', traindata_train.shape)\n",
    "print('traindata_test:', traindata_test.shape)\n",
    "print('x_train:', x_train.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('x_test:', x_test.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000746 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1589\n",
      "[LightGBM] [Info] Number of data points in the train set: 105024, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 1.050845\n"
     ]
    }
   ],
   "source": [
    "gbr_reg = GradientBoostingRegressor(n_estimators=100, random_state=42).fit(x_train, y_train)\n",
    "lgb_reg = lgb.LGBMRegressor(random_state=42, n_estimators=100, n_jobs=20).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2020_pred8 = predpnc(gbr_reg, x_test, y_test, traindata_test)\n",
    "data2020_pred9 = predpnc(lgb_reg, x_test, y_test, data2020_pred8)\n",
    "data2020_pred9.columns = ['sta', 'cams', 'radiation', 'temperature', 'precipitation',\n",
    "                          'humidity', 'Speed', 'road', 'hour', 'month', 'weekday',\n",
    "                          'measurements', 'gbr_pred','gbr_resid',\n",
    "                          'lgb_pred','lgb_resid']\n",
    "pred_table_path = '../out/pred_table/'\n",
    "# data2020_pred9.to_csv(pred_table_path + pollution + '_data2020_pred.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
